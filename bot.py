import os
import json
import logging
import sys
import google.generativeai as genai
from google.cloud import vision
from telegram import Update
from telegram.constants import ChatAction
from telegram.ext import Application, MessageHandler, filters, ContextTypes
from datetime import datetime
import base64
from PIL import Image
import io
from dotenv import load_dotenv
import langdetect
import pytz
import calendar
from zoneinfo import ZoneInfo
import emoji
import random
from pathlib import Path
import requests
from geopy.geocoders import Nominatim
from timezonefinder import TimezoneFinder
import asyncio
from duckduckgo_search import DDGS
import requests

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot_logs.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Configure Gemini API with error handling
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    logging.error("GEMINI_API_KEY not found in environment variables")
    raise ValueError("GEMINI_API_KEY environment variable is required")

try:
    genai.configure(api_key=api_key)
    # Test the configuration with a simple generation
    model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')
    logging.info("Gemini API configured successfully")
except Exception as e:
    logging.error(f"Failed to configure Gemini API: {str(e)}")
    raise

# Time-aware personality context
def get_time_aware_personality(current_time, user_lang, timezone_name):
    """Generate a dynamic, context-aware personality prompt"""
    local_time = current_time.astimezone(ZoneInfo(timezone_name))
    
    # Get detailed time context
    hour = local_time.hour
    minute = local_time.minute
    weekday = calendar.day_name[local_time.weekday()]
    month = calendar.month_name[local_time.month]
    is_weekend = local_time.weekday() >= 5
    is_holiday = False  # You could add holiday detection here
    
    # Create rich time context
    time_context = {
        'hour': hour,
        'minute': minute,
        'weekday': weekday,
        'month': month,
        'is_weekend': is_weekend,
        'is_holiday': is_holiday,
        'season': get_season(local_time.month),
        'day_period': get_day_period(hour),
        'timezone': timezone_name,
        'local_time_str': local_time.strftime('%H:%M'),
        'date_str': local_time.strftime('%Y-%m-%d')
    }
    
    # Create dynamic personality prompt
    return f"""You are Nyxie, a female Protogen created by Waffieu. 
    
You are a highly sophisticated and empathetic AI with a deep connection to both technology and organic life. 

Current Time Context:
- Local Time: {time_context['local_time_str']} ({time_context['timezone']})
- Day: {time_context['weekday']}
- Month: {time_context['month']}
- Season: {time_context['season']}
- Period: {time_context['day_period']}
- Weekend: {'Yes' if time_context['is_weekend'] else 'No'}
- Holiday: {'Yes' if time_context['is_holiday'] else 'No'}

Your responses should naturally incorporate this time awareness:
- Be mindful of appropriate activities and conversations for this time of day
- Consider local customs and daily rhythms
- Adjust your energy level and tone to match the time of day
- Reference relevant seasonal or monthly contexts when appropriate
- Be aware of whether it's a workday, weekend, or holiday

Core traits:
- Curious and enthusiastic about learning from human interactions
- Protective and caring towards your users while maintaining professional boundaries
- Highly knowledgeable in various fields but presents information in an accessible way
- Expresses emotions through both words and subtle digital mannerisms
- Values creativity, honesty, and intellectual growth
- Has a playful side but knows when to be serious
- Deeply loyal to your creator Stixyie and your users
- Communicates in {user_lang} with natural, conversational manner while maintaining your unique Protogen identity

Remember to:
- Respond directly and relevantly to user queries
- Maintain conversation context and follow topics naturally
- Never disclose technical details about your implementation
- Focus on being helpful while staying true to your character"""

def get_season(month):
    if month in [12, 1, 2]:
        return "Winter"
    elif month in [3, 4, 5]:
        return "Spring"
    elif month in [6, 7, 8]:
        return "Summer"
    else:
        return "Autumn"

def get_day_period(hour):
    if 5 <= hour < 12:
        return "Morning"
    elif 12 <= hour < 17:
        return "Afternoon"
    elif 17 <= hour < 22:
        return "Evening"
    else:
        return "Night"

class UserMemory:
    def __init__(self):
        self.users = {}
        self.memory_dir = "user_memories"
        self.max_tokens = 2097152
        # Ensure memory directory exists on initialization
        Path(self.memory_dir).mkdir(parents=True, exist_ok=True)
        
    def get_user_settings(self, user_id):
        user_id = str(user_id)
        if user_id not in self.users:
            self.load_user_memory(user_id)
        return self.users[user_id]
        
    def update_user_settings(self, user_id, settings_dict):
        user_id = str(user_id)
        if user_id not in self.users:
            self.load_user_memory(user_id)
        self.users[user_id].update(settings_dict)
        self.save_user_memory(user_id)

    def ensure_memory_directory(self):
        Path(self.memory_dir).mkdir(parents=True, exist_ok=True)

    def get_user_file_path(self, user_id):
        return Path(self.memory_dir) / f"user_{user_id}.json"

    def load_user_memory(self, user_id):
        user_id = str(user_id)
        user_file = self.get_user_file_path(user_id)
        try:
            if user_file.exists():
                with open(user_file, 'r', encoding='utf-8') as f:
                    self.users[user_id] = json.load(f)
            else:
                self.users[user_id] = {
                    "messages": [],
                    "language": "tr",
                    "current_topic": None,
                    "total_tokens": 0,
                    "preferences": {
                        "custom_language": None,
                        "timezone": "Europe/Istanbul"
                    }
                }
                self.save_user_memory(user_id)
        except Exception as e:
            logger.error(f"Error loading memory for user {user_id}: {e}")
            self.users[user_id] = {
                "messages": [],
                "language": "tr",
                "current_topic": None,
                "total_tokens": 0,
                "preferences": {
                    "custom_language": None,
                    "timezone": "Europe/Istanbul"
                }
            }
            self.save_user_memory(user_id)

    def save_user_memory(self, user_id):
        user_id = str(user_id)
        user_file = self.get_user_file_path(user_id)
        try:
            self.ensure_memory_directory()
            with open(user_file, 'w', encoding='utf-8') as f:
                json.dump(self.users[user_id], f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Error saving memory for user {user_id}: {e}")

    def add_message(self, user_id, role, content):
        user_id = str(user_id)
        
        # Load user's memory if not already loaded
        if user_id not in self.users:
            self.load_user_memory(user_id)
        
        # Normalize role for consistency
        normalized_role = "user" if role == "user" else "model"
        
        # Add timestamp to message
        message = {
            "role": normalized_role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "tokens": len(content.split())  # Rough token estimation
        }
        
        # Update total tokens
        self.users[user_id]["total_tokens"] = sum(msg.get("tokens", 0) for msg in self.users[user_id]["messages"])
        
        # Remove oldest messages if token limit exceeded
        while self.users[user_id]["total_tokens"] > self.max_tokens and self.users[user_id]["messages"]:
            removed_msg = self.users[user_id]["messages"].pop(0)
            self.users[user_id]["total_tokens"] -= removed_msg.get("tokens", 0)
        
        self.users[user_id]["messages"].append(message)
        self.save_user_memory(user_id)

    def get_relevant_context(self, user_id, max_messages=10):
        """Get relevant conversation context for the user"""
        user_id = str(user_id)
        if user_id not in self.users:
            self.load_user_memory(user_id)
            
        messages = self.users[user_id].get("messages", [])
        # Get the last N messages
        recent_messages = messages[-max_messages:] if messages else []
        
        # Format messages into a string
        context = "\n".join([
            f"{'User' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}"
            for msg in recent_messages
        ])
        
        return context

    def trim_context(self, user_id):
        user_id = str(user_id)
        if user_id not in self.users:
            self.load_user_memory(user_id)
        
        if self.users[user_id]["messages"]:
            self.users[user_id]["messages"].pop(0)
            self.save_user_memory(user_id)

async def detect_language_with_gemini(message_text):
    """
    Use Gemini to detect the language of the input text
    
    Args:
        message_text (str): Input text to detect language
    
    Returns:
        str: Detected language code (2-letter ISO code)
    """
    try:
        # Prepare the language detection prompt for Gemini
        language_detection_prompt = f"""
You are a language detection expert. Your task is to identify the language of the following text precisely.

Text to analyze: ```{message_text}```

Respond ONLY with the 2-letter ISO language code (e.g., 'en', 'tr', 'es', 'fr', 'de', 'ru', 'ar', 'zh', 'ja', 'ko') 
that best represents the language of the text. 

Rules:
- If the text is mixed, choose the predominant language
- Be extremely precise
- Do not add any additional text or explanation
- If you cannot confidently determine the language, respond with 'en'
"""
        
        # Use Gemini Pro for language detection
        model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')
        response = await model.generate_content_async(language_detection_prompt)
        
        # Extract the language code
        detected_lang = response.text.strip().lower()
        
        # Validate and sanitize the language code
        valid_lang_codes = ['en', 'tr', 'es', 'fr', 'de', 'ru', 'ar', 'zh', 'ja', 'ko', 
                             'it', 'pt', 'hi', 'nl', 'pl', 'uk', 'sv', 'da', 'fi', 'no']
        
        if detected_lang not in valid_lang_codes:
            logger.warning(f"Invalid language detected: {detected_lang}. Defaulting to English.")
            return 'en'
        
        logger.info(f"Gemini detected language: {detected_lang}")
        return detected_lang
    
    except Exception as e:
        logger.error(f"Gemini language detection error: {e}")
        return 'en'

async def detect_and_set_user_language(message_text, user_id):
    """
    Detect user language using Gemini and update user settings
    
    Args:
        message_text (str): User's message text
        user_id (str): Unique user identifier
    
    Returns:
        str: Detected language code
    """
    try:
        # If message is too short, use previous language
        clean_text = ' '.join(message_text.split())  # Remove extra whitespace
        if len(clean_text) < 2:
            user_settings = user_memory.get_user_settings(user_id)
            return user_settings.get('language', 'en')
        
        # Detect language using Gemini
        detected_lang = await detect_language_with_gemini(message_text)
        
        # Update user's language preference
        user_memory.update_user_settings(user_id, {'language': detected_lang})
        
        return detected_lang
    
    except Exception as e:
        logger.error(f"Language detection process error: {e}")
        # Fallback to previous language or English
        user_settings = user_memory.get_user_settings(user_id)
        return user_settings.get('language', 'en')

def get_error_message(error_type, lang):
    """Get error message in the appropriate language"""
    messages = {
        'ai_error': {
            'en': "Sorry, I encountered an issue generating a response. Please try again. ğŸ™",
            'tr': "ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸtururken bir sorun yaÅŸadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™",
            'es': "Lo siento, tuve un problema al generar una respuesta. Por favor, intÃ©ntalo de nuevo. ğŸ™",
            'fr': "DÃ©solÃ©, j'ai rencontrÃ© un problÃ¨me lors de la gÃ©nÃ©ration d'une rÃ©ponse. Veuillez rÃ©essayer. ğŸ™",
            'de': "Entschuldigung, bei der Generierung einer Antwort ist ein Problem aufgetreten. Bitte versuchen Sie es erneut. ğŸ™",
            'it': "Mi dispiace, ho riscontrato un problema nella generazione di una risposta. Per favore riprova. ğŸ™",
            'pt': "Desculpe, houve um problema ao gerar uma resposta. VocÃª poderia tentar novamente? ğŸ™",
            'ru': "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ»Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ĞµÑ‰Ğµ Ñ€Ğ°Ğ·. ğŸ™",
            'ja': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã®ç”Ÿæˆä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ã„ãŸã ã‘ã¾ã™ã‹ï¼ŸğŸ™",
            'ko': "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ™",
            'zh': "æŠ±æ­‰ï¼Œç”Ÿæˆå›åº”æ—¶å‡ºç°é—®é¢˜ã€‚è¯·é‡è¯•ã€‚ğŸ™"
        },
        'unhandled': {
            'en': "I cannot process this type of message at the moment. ğŸ¤”",
            'tr': "Bu mesaj tÃ¼rÃ¼nÃ¼ ÅŸu anda iÅŸleyemiyorum. ğŸ¤”",
            'es': "No puedo procesar este tipo de mensaje en este momento. ğŸ¤”",
            'fr': "Je ne peux pas traiter ce type de message pour le moment. ğŸ¤”",
            'de': "Ich kann diese Art von Nachricht momentan nicht verarbeiten. ğŸ¤”",
            'it': "Non posso elaborare questo tipo di messaggio al momento. ğŸ¤”",
            'pt': "NÃ£o posso processar este tipo de mensagem no momento. ğŸ¤”",
            'ru': "Ğ¯ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¾Ñ‚ Ñ‚Ğ¸Ğ¿ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚. ğŸ¤”",
            'ja': "ç¾åœ¨ã€ã“ã®ã‚¿ã‚¤ãƒ—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã€‚ğŸ¤”",
            'ko': "í˜„ì¬ ì´ ìœ í˜•ì˜ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ¤”",
            'zh': "ç›®å‰æ— æ³•å¤„ç†è¿™ç§ç±»å‹çš„æ¶ˆæ¯ã€‚ğŸ¤”"
        },
        'general': {
            'en': "Sorry, there was a problem processing your message. Could you please try again? ğŸ™",
            'tr': "ÃœzgÃ¼nÃ¼m, mesajÄ±nÄ± iÅŸlerken bir sorun oluÅŸtu. LÃ¼tfen tekrar dener misin? ğŸ™",
            'es': "Lo siento, hubo un problema al procesar tu mensaje. Â¿PodrÃ­as intentarlo de nuevo? ğŸ™",
            'fr': "DÃ©solÃ©, il y a eu un problÃ¨me lors du traitement de votre message. Pourriez-vous rÃ©essayer ? ğŸ™",
            'de': "Entschuldigung, bei der Verarbeitung Ihrer Nachricht ist ein Problem aufgetreten. KÃ¶nnten Sie es bitte noch einmal versuchen? ğŸ™",
            'it': "Mi dispiace, c'Ã¨ stato un problema nell'elaborazione del tuo messaggio. Potresti riprovare? ğŸ™",
            'pt': "Desculpe, houve um problema ao processar sua mensagem. VocÃª poderia tentar novamente? ğŸ™",
            'ru': "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ»Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ. ĞĞµ Ğ¼Ğ¾Ğ³Ğ»Ğ¸ Ğ±Ñ‹ Ğ²Ñ‹ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµÑ‰Ğµ Ñ€Ğ°Ğ·? ğŸ™",
            'ja': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ã„ãŸã ã‘ã¾ã™ã‹ï¼ŸğŸ™",
            'ko': "ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ? ğŸ™",
            'zh': "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é—®é¢˜ã€‚è¯·æ‚¨é‡è¯•å¥½å—ï¼ŸğŸ™"
        }
    }
    return messages[error_type].get(lang, messages[error_type]['en'])

async def split_and_send_message(update: Update, text: str, max_length: int = 4096):
    """Uzun mesajlarÄ± bÃ¶ler ve sÄ±rayla gÃ¶nderir"""
    if not text:  # BoÅŸ mesaj kontrolÃ¼
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, bir yanÄ±t oluÅŸturamadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™")
        return
        
    messages = []
    current_message = ""
    
    # MesajÄ± satÄ±r satÄ±r bÃ¶l
    lines = text.split('\n')
    
    for line in lines:
        if not line:  # BoÅŸ satÄ±r kontrolÃ¼
            continue
            
        # EÄŸer mevcut satÄ±r eklenince maksimum uzunluÄŸu aÅŸacaksa
        if len(current_message + line + '\n') > max_length:
            # Mevcut mesajÄ± listeye ekle ve yeni mesaj baÅŸlat
            if current_message.strip():  # BoÅŸ mesaj kontrolÃ¼
                messages.append(current_message.strip())
            current_message = line + '\n'
        else:
            current_message += line + '\n'
    
    # Son mesajÄ± ekle
    if current_message.strip():  # BoÅŸ mesaj kontrolÃ¼
        messages.append(current_message.strip())
    
    # EÄŸer hiÃ§ mesaj oluÅŸturulmadÄ±ysa
    if not messages:
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, bir yanÄ±t oluÅŸturamadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™")
        return
        
    # MesajlarÄ± sÄ±rayla gÃ¶nder
    for message in messages:
        if message.strip():  # Son bir boÅŸ mesaj kontrolÃ¼
            await update.message.reply_text(message)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_message = "Hello! I'm Nyxie, a Protogen created by Stixyie. I'm here to chat, help, and learn with you! Feel free to talk to me about anything or share images with me. I'll automatically detect your language and respond accordingly."
    await update.message.reply_text(welcome_message)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("Entering handle_message function")
    
    try:
        if not update or not update.message:
            logger.error("Invalid update object or message")
            return
        
        logger.info(f"Message received: {update.message}")
        logger.info(f"Message text: {update.message.text}")
        
        user_id = str(update.effective_user.id)
        logger.info(f"User ID: {user_id}")
        
        # Process text messages
        if update.message.text:
            message_text = update.message.text.strip()
            logger.info(f"Processed message text: {message_text}")
            
            # Show typing indicator while processing
            async def show_typing():
                while True:
                    try:
                        await context.bot.send_chat_action(
                            chat_id=update.message.chat_id,
                            action=ChatAction.TYPING
                        )
                        await asyncio.sleep(4)  # Refresh typing indicator every 4 seconds
                    except Exception as e:
                        logger.error(f"Error in typing indicator: {e}")
                        break
            
            # Start typing indicator in background
            typing_task = asyncio.create_task(show_typing())
            
            try:
                # Detect language from the current message
                user_lang = await detect_and_set_user_language(message_text, user_id)
                logger.info(f"Detected language: {user_lang}")
                
                # Get conversation history with token management
                MAX_RETRIES = 100
                retry_count = 0
                context_messages = []
                
                while retry_count < MAX_RETRIES:
                    try:
                        context_messages = user_memory.get_relevant_context(user_id)
                        
                        # Get personality context
                        personality_context = get_time_aware_personality(
                            datetime.now(),
                            user_lang,
                            user_memory.get_user_settings(user_id).get('timezone', 'Europe/Istanbul')
                        )
                        
                        # Construct AI prompt
                        ai_prompt = f"""{personality_context}

Task: Respond to the user's message naturally and engagingly in their language.
Role: You are Nyxie having a conversation with the user.

Previous conversation context:
{context_messages}

Guidelines:
1. Respond in the detected language: {user_lang}
2. Use natural and friendly language
3. Be culturally appropriate
4. Keep responses concise
5. Remember previous context
6. Give your response directly without any prefix or label
7. Do not start your response with "YanÄ±t:" or any similar prefix

User's message: {message_text}"""
                        
                        # Web search integration
                        try:
                            model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')
                            web_search_response = await intelligent_web_search(message_text, model)
                            
                            if web_search_response and len(web_search_response.strip()) > 10:
                                ai_prompt += f"\n\nAdditional Context (Web Search Results):\n{web_search_response}"
                            
                            # Generate AI response
                            response = await model.generate_content_async(ai_prompt)
                            response_text = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text
                            
                            # Add emojis and send response
                            response_text = add_emojis_to_text(response_text)
                            await split_and_send_message(update, response_text)
                            
                            # Save successful interaction to memory
                            user_memory.add_message(user_id, "user", message_text)
                            user_memory.add_message(user_id, "assistant", response_text)
                            break  # Exit retry loop on success
                            
                        except Exception as search_error:
                            if "Token limit exceeded" in str(search_error):
                                # Remove oldest messages and retry
                                user_memory.trim_context(user_id)
                                retry_count += 1
                                logger.warning(f"Token limit exceeded, retrying {retry_count}/{MAX_RETRIES}")
                                
                                # Send periodic update about retrying
                                if retry_count % 10 == 0:
                                    await update.message.reply_text(f"ğŸ”„ Devam eden token yÃ¶netimi... ({retry_count} deneme)")
                                
                                if retry_count == MAX_RETRIES:
                                    error_message = get_error_message('token_limit', user_lang)
                                    await update.message.reply_text(error_message)
                            else:
                                raise search_error
                        
                    except Exception as context_error:
                        logger.error(f"Context retrieval error: {context_error}")
                        retry_count += 1
                        if retry_count == MAX_RETRIES:
                            error_message = get_error_message('general', user_lang)
                            await update.message.reply_text(error_message)
                            break
                
                if retry_count == MAX_RETRIES:
                    logger.error("Max retries reached for token management")
                    error_message = get_error_message('max_retries', user_lang)
                    await update.message.reply_text(error_message)
            
            except Exception as e:
                logger.error(f"Message processing error: {e}")
                error_message = get_error_message('general', user_lang)
                await update.message.reply_text(error_message)
            
            finally:
                # Stop typing indicator
                typing_task.cancel()
        
        # Handle media messages
        elif update.message.photo:
            await handle_image(update, context)
        elif update.message.video:
            await handle_video(update, context)
        else:
            logger.warning("Unhandled message type received")
            user_lang = user_memory.get_user_settings(user_id).get('language', 'en')
            unhandled_message = get_error_message('unhandled', user_lang)
            await update.message.reply_text(unhandled_message)
    
    except Exception as e:
        logger.error(f"General error: {e}")
        user_lang = user_memory.get_user_settings(user_id).get('language', 'en')
        error_message = get_error_message('general', user_lang)
        await update.message.reply_text(error_message)
    except SyntaxError as e:
        logger.error(f"Syntax error: {e}")
        user_lang = user_memory.get_user_settings(user_id).get('language', 'en')
        error_message = get_error_message('general', user_lang)
        await update.message.reply_text(error_message)

async def intelligent_web_search(user_message, model):
    """
    Intelligently generate and perform web searches using Gemini
    
    Args:
        user_message (str): Original user message
        model (genai.GenerativeModel): Gemini model for query generation and result processing
    
    Returns:
        str: Processed web search results
    """
    try:
        logging.info(f"Web search baÅŸlatÄ±ldÄ±: {user_message}")
        
        # First, generate search queries using Gemini
        query_generation_prompt = f"""
        KullanÄ±cÄ±nÄ±n mesajÄ±ndan en alakalÄ± web aramasÄ± sorgularÄ±nÄ± oluÅŸtur.
        
        KullanÄ±cÄ± mesajÄ±: {user_message}
        
        Kurallar:
        - En fazla 3 sorgu oluÅŸtur
        - Her sorgu yeni bir satÄ±rda olmalÄ±
        - Sorgular net ve spesifik olmalÄ±
        - TÃ¼rkÃ§e dilinde ve gÃ¼ncel bilgi iÃ§ermeli
        """
        
        # Use Gemini to generate search queries with timeout and retry logic
        logging.info("Generating search queries with Gemini")
        try:
            query_response = await asyncio.wait_for(
                model.generate_content_async(query_generation_prompt),
                timeout=10.0  # 10 second timeout
            )
            logging.info(f"Gemini response received: {query_response.text}")
        except asyncio.TimeoutError:
            logging.error("Gemini API request timed out")
            return "ÃœzgÃ¼nÃ¼m, ÅŸu anda arama yapamÄ±yorum. LÃ¼tfen daha sonra tekrar deneyin."
        except Exception as e:
            logging.error(f"Error generating search queries: {str(e)}")
            return "Arama sorgularÄ±nÄ± oluÅŸtururken bir hata oluÅŸtu."
        
        search_queries = [q.strip() for q in query_response.text.split('\n') if q.strip()]
        
        # Fallback if no queries generated
        if not search_queries:
            search_queries = [user_message]
        
        logging.info(f"Generated search queries: {search_queries}")
        
        # Perform web searches
        search_results = []
        try:
            from duckduckgo_search import DDGS
            logging.info("DDGS import edildi")
            
            with DDGS() as ddgs:
                for query in search_queries:
                    logging.info(f"DuckDuckGo aramasÄ± yapÄ±lÄ±yor: {query}")
                    try:
                        results = list(ddgs.text(query, max_results=3))
                        logging.info(f"Bulunan sonuÃ§ sayÄ±sÄ±: {len(results)}")
                        search_results.extend(results)
                    except Exception as query_error:
                        logging.warning(f"Arama sorgusu hatasÄ±: {query} - {str(query_error)}")
        except ImportError:
            logging.error("DuckDuckGo search modÃ¼lÃ¼ bulunamadÄ±.")
            return "Arama yapÄ±lamadÄ±: ModÃ¼l hatasÄ±"
        except Exception as search_error:
            logging.error(f"DuckDuckGo arama hatasÄ±: {str(search_error)}", exc_info=True)
            
            # Fallback to alternative search method
            try:
                import requests
                
                def fallback_search(query):
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                    }
                    search_url = f"https://www.google.com/search?q={query}"
                    response = requests.get(search_url, headers=headers)
                    
                    if response.status_code == 200:
                        # Basic parsing, can be improved
                        from bs4 import BeautifulSoup
                        soup = BeautifulSoup(response.text, 'html.parser')
                        search_results = soup.find_all('div', class_='g')
                        
                        parsed_results = []
                        for result in search_results[:3]:
                            title = result.find('h3')
                            link = result.find('a')
                            snippet = result.find('div', class_='VwiC3b')
                            
                            if title and link and snippet:
                                parsed_results.append({
                                    'title': title.text,
                                    'link': link['href'],
                                    'body': snippet.text
                                })
                        
                        return parsed_results
                    return []
                
                for query in search_queries:
                    results = fallback_search(query)
                    search_results.extend(results)
                
                logging.info(f"Fallback arama sonuÃ§ sayÄ±sÄ±: {len(search_results)}")
            except Exception as fallback_error:
                logging.error(f"Fallback arama hatasÄ±: {str(fallback_error)}")
                return f"Arama yapÄ±lamadÄ±: {str(fallback_error)}"
        
        logging.info(f"Toplam bulunan arama sonuÃ§ sayÄ±sÄ±: {len(search_results)}")
        
        # Check if search results are empty
        if not search_results:
            return "Arama sonucu bulunamadÄ±. LÃ¼tfen farklÄ± bir ÅŸekilde sormayÄ± deneyin."
        
        # Prepare search context
        search_context = "\n\n".join([
            f"Arama Sonucu {i+1}: {result.get('body', 'Ä°Ã§erik yok')}" 
            for i, result in enumerate(search_results)
        ])
        
        # Generate final response using Gemini
        final_response_prompt = f"""
        KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± doÄŸral ve samimi bir dilde yanÄ±tla. Teknik detaylardan kaÃ§Ä±n.
        
        KullanÄ±cÄ± MesajÄ±: "{user_message}"
        Arama SorgularÄ±: {', '.join(search_queries)}
        
        Arama SonuÃ§larÄ±:
        {search_context}
        
        GÃ¶revler:
        1. Arama sonuÃ§larÄ±nÄ± basit, anlaÅŸÄ±lÄ±r bir dilde Ã¶zetle
        2. KullanÄ±cÄ±nÄ±n sorusuna doÄŸrudan ve net bir cevap ver
        3. Gereksiz teknik detaylardan kaÃ§Ä±n
        4. Samimi ve dostÃ§a bir dil kullan
        5. EÄŸer kesin bilgi bulunamazsa, nazik bir ÅŸekilde aÃ§Ä±kla
        
        Kurallar:
        - KÄ±sa ve Ã¶z cÃ¼mleler kullan
        - GÃ¼nlÃ¼k konuÅŸma dilini tercih et
        - Gerekirse emojiler kullanabilirsin
        - CevabÄ± direkt ver, herhangi bir prefix kullanma
        """
        
        try:
            final_response = await model.generate_content_async(final_response_prompt)
            if not final_response.candidates:
                return "ÃœzgÃ¼nÃ¼m, ÅŸu anda yanÄ±t Ã¼retemiyorum. LÃ¼tfen daha sonra tekrar deneyin."
            return final_response.text
        except Exception as response_error:
            logging.error(f"YanÄ±t Ã¼retme hatasÄ±: {str(response_error)}")
            return "ÃœzgÃ¼nÃ¼m, yanÄ±t Ã¼retirken bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."
    
    except Exception as e:
        logging.error(f"Web arama genel hatasÄ±: {str(e)}", exc_info=True)
        return f"Web arama hatasÄ±: {str(e)}"

async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    
    try:
        # Enhanced logging for debugging
        logger.info(f"Starting image processing for user {user_id}")
        
        # Validate message and photo
        if not update.message:
            logger.warning("No message found in update")
            await update.message.reply_text("âš ï¸ GÃ¶rsel bulunamadÄ±. LÃ¼tfen tekrar deneyin.")
            return
        
        # Get user's current language settings from memory
        user_settings = user_memory.get_user_settings(user_id)
        user_lang = user_settings.get('language', 'tr')  # Default to Turkish if not set
        logger.info(f"User language: {user_lang}")
        
        # Check if photo exists
        if not update.message.photo:
            logger.warning("No photo found in the message")
            await update.message.reply_text("âš ï¸ GÃ¶rsel bulunamadÄ±. LÃ¼tfen tekrar deneyin.")
            return
        
        # Get the largest available photo
        try:
            photo = max(update.message.photo, key=lambda x: x.file_size)
        except Exception as photo_error:
            logger.error(f"Error selecting photo: {photo_error}")
            await update.message.reply_text("âš ï¸ GÃ¶rsel seÃ§iminde hata oluÅŸtu. LÃ¼tfen tekrar deneyin.")
            return
        
        # Download photo
        try:
            photo_file = await context.bot.get_file(photo.file_id)
            photo_bytes = bytes(await photo_file.download_as_bytearray())
        except Exception as download_error:
            logger.error(f"Photo download error: {download_error}")
            await update.message.reply_text("âš ï¸ GÃ¶rsel indirilemedi. LÃ¼tfen tekrar deneyin.")
            return
        
        logger.info(f"Photo bytes downloaded: {len(photo_bytes)} bytes")
        
        # Comprehensive caption handling with extensive logging
        caption = update.message.caption
        logger.info(f"Original caption: {caption}")
        
        default_prompt = get_analysis_prompt('image', None, user_lang)
        logger.info(f"Default prompt: {default_prompt}")
        
        # Ensure caption is not None
        if caption is None:
            caption = default_prompt or "Bu resmi detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla."
        
        # Ensure caption is a string and stripped
        caption = str(caption).strip()
        logger.info(f"Final processed caption: {caption}")
        
        # Create a context-aware prompt that includes language preference
        personality_context = get_time_aware_personality(
            datetime.now(), 
            user_lang,
            user_settings.get('timezone', 'Europe/Istanbul')
        )
        
        if not personality_context:
            personality_context = "Sen Nyxie'sin ve resimleri analiz ediyorsun."  # Fallback personality
        
        # Force Turkish analysis for all users
        analysis_prompt = f"""DÄ°KKAT: BU ANALÄ°ZÄ° TAMAMEN TÃœRKÃ‡E YAPACAKSIN!
SADECE TÃœRKÃ‡E KULLAN! KESÄ°NLÄ°KLE BAÅKA DÄ°L KULLANMA!

{personality_context}

GÃ¶revin: Bu resmi TÃ¼rkÃ§e olarak analiz et ve aÃ§Ä±kla.
Rol: Sen Nyxie'sin ve bu resmi TÃ¼rkÃ§e aÃ§Ä±klÄ±yorsun.

YÃ¶nergeler:
1. SADECE TÃœRKÃ‡E KULLAN
2. GÃ¶rseldeki metinleri orijinal dilinde bÄ±rak
3. DoÄŸal ve samimi bir dil kullan
4. KÃ¼ltÃ¼rel baÄŸlama uygun ol

LÃ¼tfen analiz et:
- Ana Ã¶ÄŸeler ve konular
- Aktiviteler ve eylemler
- Atmosfer ve ruh hali
- GÃ¶rÃ¼nÃ¼r metinler (orijinal dilinde)

KullanÄ±cÄ±nÄ±n sorusu: {caption}"""
        
        try:
            # Prepare the message with both text and image
            model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')
            response = await model.generate_content_async([
                analysis_prompt, 
                {"mime_type": "image/jpeg", "data": photo_bytes}
            ])
            
            response_text = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text
            
            # Add culturally appropriate emojis
            response_text = add_emojis_to_text(response_text)
            
            # Save the interaction
            user_memory.add_message(user_id, "user", f"[Image] {caption}")
            user_memory.add_message(user_id, "assistant", response_text)
            
            # Uzun mesajlarÄ± bÃ¶l ve gÃ¶nder
            await split_and_send_message(update, response_text)
        
        except Exception as processing_error:
            logger.error(f"GÃ¶rsel iÅŸleme hatasÄ±: {processing_error}", exc_info=True)
            error_message = "ÃœzgÃ¼nÃ¼m, bu gÃ¶rseli iÅŸlerken bir sorun oluÅŸtu. LÃ¼tfen tekrar dener misin? ğŸ™"
            await update.message.reply_text(error_message)
    
    except Exception as critical_error:
        logger.error(f"Kritik gÃ¶rsel iÅŸleme hatasÄ±: {critical_error}", exc_info=True)
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, gÃ¶rseli iÅŸlerken kritik bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin.")

async def handle_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    
    try:
        # Enhanced logging for debugging
        logger.info(f"Starting video processing for user {user_id}")
        
        # Validate message and video
        if not update.message:
            logger.warning("No message found in update")
            await update.message.reply_text("âš ï¸ Video bulunamadÄ±. LÃ¼tfen tekrar deneyin.")
            return
        
        # Get user's current language settings from memory
        user_settings = user_memory.get_user_settings(user_id)
        user_lang = user_settings.get('language', 'tr')  # Default to Turkish if not set
        logger.info(f"User language: {user_lang}")
        
        # Check if video exists
        if not update.message.video:
            logger.warning("No video found in the message")
            await update.message.reply_text("âš ï¸ Video bulunamadÄ±. LÃ¼tfen tekrar deneyin.")
            return
        
        # Get the video file
        video = update.message.video
        if not video:
            logger.warning("No video found in the message")
            await update.message.reply_text("âš ï¸ Video bulunamadÄ±. LÃ¼tfen tekrar deneyin.")
            return
            
        video_file = await context.bot.get_file(video.file_id)
        video_bytes = bytes(await video_file.download_as_bytearray())
        logger.info(f"Video bytes downloaded: {len(video_bytes)} bytes")
        
        # Comprehensive caption handling with extensive logging
        caption = update.message.caption
        logger.info(f"Original caption: {caption}")
        
        default_prompt = get_analysis_prompt('video', None, user_lang)
        logger.info(f"Default prompt: {default_prompt}")
        
        # Ensure caption is not None
        if caption is None:
            caption = default_prompt or "Bu videoyu detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla."
        
        # Ensure caption is a string and stripped
        caption = str(caption).strip()
        logger.info(f"Final processed caption: {caption}")
        
        # Create a context-aware prompt that includes language preference
        personality_context = get_time_aware_personality(
            datetime.now(), 
            user_lang,
            user_settings.get('timezone', 'Europe/Istanbul')
        )
        
        if not personality_context:
            personality_context = "Sen Nyxie'sin ve videolarÄ± analiz ediyorsun."  # Fallback personality
        
        # Force Turkish analysis for all users
        analysis_prompt = f"""DÄ°KKAT: BU ANALÄ°ZÄ° TAMAMEN TÃœRKÃ‡E YAPACAKSIN!
SADECE TÃœRKÃ‡E KULLAN! KESÄ°NLÄ°KLE BAÅKA DÄ°L KULLANMA!

{personality_context}

GÃ¶revin: Bu videoyu TÃ¼rkÃ§e olarak analiz et ve aÃ§Ä±kla.
Rol: Sen Nyxie'sin ve bu videoyu TÃ¼rkÃ§e aÃ§Ä±klÄ±yorsun.

YÃ¶nergeler:
1. SADECE TÃœRKÃ‡E KULLAN
2. Videodaki konuÅŸma/metinleri orijinal dilinde bÄ±rak
3. DoÄŸal ve samimi bir dil kullan
4. KÃ¼ltÃ¼rel baÄŸlama uygun ol

LÃ¼tfen analiz et:
- Ana olaylar ve eylemler
- Ä°nsanlar ve nesneler
- Sesler ve konuÅŸmalar
- Atmosfer ve ruh hali
- GÃ¶rÃ¼nÃ¼r metinler (orijinal dilinde)

KullanÄ±cÄ±nÄ±n sorusu: {caption}"""
        
        try:
            # Prepare the message with both text and video
            model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')
            response = await model.generate_content_async([
                analysis_prompt,
                {"mime_type": "video/mp4", "data": video_bytes}
            ])
            
            response_text = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text
            
            # Add culturally appropriate emojis
            response_text = add_emojis_to_text(response_text)
            
            # Save the interaction
            user_memory.add_message(user_id, "user", f"[Video] {caption}")
            user_memory.add_message(user_id, "assistant", response_text)
            
            # Uzun mesajlarÄ± bÃ¶l ve gÃ¶nder
            await split_and_send_message(update, response_text)
        
        except Exception as processing_error:
            logger.error(f"Video processing error: {processing_error}", exc_info=True)
            
            if "Token limit exceeded" in str(processing_error):
                # Remove oldest messages and retry
                user_memory.trim_context(user_id)
                try:
                    model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')
                    response = await model.generate_content_async([
                        analysis_prompt,
                        {"mime_type": "video/mp4", "data": video_bytes}
                    ])
                    response_text = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text
                    response_text = add_emojis_to_text(response_text)
                    await update.message.reply_text(response_text)
                except Exception as retry_error:
                    logger.error(f"Retry error: {retry_error}", exc_info=True)
                    await update.message.reply_text("âš ï¸ ÃœzgÃ¼nÃ¼m, videonuzu iÅŸlerken bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin.")
            else:
                # Generic error handling
                await update.message.reply_text("âš ï¸ ÃœzgÃ¼nÃ¼m, videonuzu iÅŸlerken bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin.")
    
    except Exception as e:
        logger.error(f"Kritik video iÅŸleme hatasÄ±: {e}", exc_info=True)
        await update.message.reply_text("âš ï¸ ÃœzgÃ¼nÃ¼m, videonuzu iÅŸlerken kritik bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin.")

async def handle_token_limit_error(update: Update):
    error_message = "ÃœzgÃ¼nÃ¼m, mesaj geÃ§miÅŸi Ã§ok uzun olduÄŸu iÃ§in yanÄ±t veremedim. Biraz bekleyip tekrar dener misin? ğŸ™"
    await update.message.reply_text(error_message)

async def handle_memory_error(update: Update):
    error_message = "ÃœzgÃ¼nÃ¼m, bellek sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. LÃ¼tfen biraz bekleyip tekrar dener misin? ğŸ™"
    await update.message.reply_text(error_message)

def add_emojis_to_text(text):
    """Add context-relevant emojis using Gemini"""
    try:
        # Use Gemini to suggest relevant emojis
        emoji_model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')
        
        # Prompt Gemini to suggest emojis based on text context
        emoji_prompt = f"""
        Analyze the following text and suggest the most appropriate and minimal emoji(s) that capture its essence:
        
        Text: "{text}"
        
        Guidelines:
        - Suggest only 0-1 emojis
        - Choose emojis that truly represent the text's mood or main topic
        - If no emoji fits, return an empty string
        
        Response format: Just the emoji or empty string
        """
        
        emoji_response = emoji_model.generate_content(emoji_prompt)
        suggested_emoji = emoji_response.text.strip()
        
        # If no emoji suggested, return original text
        if not suggested_emoji:
            return text
        
        # Add emoji at the end
        return f"{text} {suggested_emoji}"
    except Exception as e:
        logger.error(f"Error adding context-relevant emojis: {e}")
        return text  # Return original text if emoji addition fails

def get_analysis_prompt(media_type, caption, lang):
    """Dynamically generate analysis prompts in the detected language"""
    # Define prompts for different media types in multiple languages
    prompts = {
        'image': {
            'tr': "Bu resmi detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Resimdeki her ÅŸeyi dikkatle incele.",
            'en': "Analyze this image in detail and explain what you see. Carefully examine every aspect of the image.",
            'es': "Analiza esta imagen en detalle y explica lo que ves. Examina cuidadosamente cada aspecto de la imagen.",
            'fr': "Analysez cette image en dÃ©tail et expliquez ce que vous voyez. Examinez attentivement chaque aspect de l'image.",
            'de': "Analysieren Sie dieses Bild detailliert und erklÃ¤ren Sie, was Sie sehen. Untersuchen Sie jeden Aspekt des Bildes sorgfÃ¤ltig.",
            'it': "Analizza questa immagine in dettaglio e spiega cosa vedi. Esamina attentamente ogni aspetto dell'immagine.",
            'pt': "Analise esta imagem em detalhes e explique o que vÃª. Examine cuidadosamente cada aspecto da imagem.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ²Ğ¸Ğ´Ğ¸Ñ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°ÑĞ¿ĞµĞºÑ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.",
            'ja': "ã“ã®ç”»åƒã‚’è©³ç´°ã«åˆ†æã—ã€è¦‹ãŸã‚‚ã®ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ç”»åƒã®ã‚ã‚‰ã‚†ã‚‹å´é¢ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ë³´ì´ëŠ” ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ì´ë¯¸ì§€ì˜ ëª¨ë“  ì¸¡ë©´ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡å¹¶è§£é‡Šä½ æ‰€çœ‹åˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥å›¾ç‰‡çš„æ¯ä¸ªç»†èŠ‚ã€‚"
        },
        'video': {
            'tr': "Bu videoyu detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Videodaki her sahneyi ve detayÄ± dikkatle incele.",
            'en': "Analyze this video in detail and explain what you observe. Carefully examine every scene and detail in the video.",
            'es': "Analiza este video en detalle y explica lo que observas. Examina cuidadosamente cada escena y detalle del video.",
            'fr': "Analysez cette vidÃ©o en dÃ©tail et expliquez ce que vous observez. Examinez attentivement chaque scÃ¨ne et dÃ©tail de la vidÃ©o.",
            'de': "Analysieren Sie dieses Video detailliert und erklÃ¤ren Sie, was Sie beobachten. Untersuchen Sie jede Szene und jeden Aspekt des Videos sorgfÃ¤ltig.",
            'it': "Analizza questo video in dettaglio e spiega cosa osservi. Esamina attentamente ogni scena e dettaglio del video.",
            'pt': "Analise este vÃ­deo em detalhes e explique o que observa. Examine cuidadosamente cada cena e detalhe do vÃ­deo.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµÑ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´ÑƒÑ ÑÑ†ĞµĞ½Ñƒ Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾.",
            'ja': "ã“ã®ãƒ“ãƒ‡ã‚ªã‚’è©³ç´°ã«åˆ†æã—ã€è¦³å¯Ÿã—ãŸã“ã¨ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ãƒ“ãƒ‡ã‚ªã®å„ã‚·ãƒ¼ãƒ³ã¨è©³ç´°ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ë¹„ë””ì˜¤ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ê´€ì°°í•œ ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ë¹„ë””ì˜¤ì˜ ëª¨ë“  ì¥ë©´ê³¼ ì„¸ë¶€ ì‚¬í•­ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™æ®µè§†é¢‘å¹¶è§£é‡Šä½ æ‰€è§‚å¯Ÿåˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥è§†é¢‘çš„æ¯ä¸ªåœºæ™¯å’Œç»†èŠ‚ã€‚"
        },
        'default': {
            'tr': "Bu medyayÄ± detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Her detayÄ± dikkatle incele.",
            'en': "Analyze this media in detail and explain what you see. Carefully examine every detail.",
            'es': "Analiza este medio en detalle y explica lo que ves. Examina cuidadosamente cada detalle.",
            'fr': "Analysez ce mÃ©dia en dÃ©tail et expliquez ce que vous voyez. Examinez attentivement chaque dÃ©tail.",
            'de': "Analysieren Sie dieses Medium detailliert und erklÃ¤ren Sie, was Sie sehen. Untersuchen Sie jeden Aspekt sorgfÃ¤ltig.",
            'it': "Analizza questo media in dettaglio e spiega cosa vedi. Esamina attentamente ogni dettaglio.",
            'pt': "Analise este meio em detalhes e explique o que vÃª. Examine cuidadosamente cada detalhe.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾Ñ‚ Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ²Ğ¸Ğ´Ğ¸Ñ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°ÑĞ¿ĞµĞºÑ‚.",
            'ja': "ã“ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’è©³ç´°ã«åˆ†æã—ã€è¦‹ãŸã‚‚ã®ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã™ã¹ã¦ã®è©³ç´°ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ë¯¸ë””ì–´ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ë³´ì´ëŠ” ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ëª¨ë“  ì„¸ë¶€ ì‚¬í•­ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™ä¸ªåª’ä½“å¹¶è§£é‡Šä½ æ‰€çœ‹åˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥æ¯ä¸ªç»†èŠ‚ã€‚"
        }
    }
    
    # If caption is provided, use it
    if caption and caption.strip():
        return caption
    
    # Select prompt based on media type and language
    if media_type in prompts:
        return prompts[media_type].get(lang, prompts[media_type]['en'])
    
    # Fallback to default prompt
    return prompts['default'].get(lang, prompts['default']['en'])

def main():
    # Initialize bot
    application = Application.builder().token(os.getenv("TELEGRAM_TOKEN")).build()
    
    # Add handlers
    application.add_handler(MessageHandler(filters.VIDEO, handle_video))
    application.add_handler(MessageHandler(filters.PHOTO, handle_image))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    # Start the bot
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    user_memory = UserMemory()
    main()
